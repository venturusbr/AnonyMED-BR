{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd8ba542-87eb-4d99-9443-76ecbeedc03e",
      "metadata": {
        "id": "cd8ba542-87eb-4d99-9443-76ecbeedc03e"
      },
      "outputs": [],
      "source": [
        "!pip install httpx\n",
        "!pip install pydantic_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a605571c-a5ce-465e-88b8-84173a41dfd4",
      "metadata": {
        "id": "a605571c-a5ce-465e-88b8-84173a41dfd4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "from typing import Optional, Dict\n",
        "import httpx\n",
        "from typing import Optional\n",
        "from pydantic_ai import Agent\n",
        "from pydantic_ai.models.openai import OpenAIModel\n",
        "from pydantic_ai.providers.openai import OpenAIProvider\n",
        "from datetime import datetime, timezone, timedelta\n",
        "import re\n",
        "\n",
        "def parse_json_from_code_block(output: str):\n",
        "    \"\"\"\n",
        "    Parse a JSON object from a Markdown code block.\n",
        "\n",
        "    This function removes Markdown code fences (```json ... ```)\n",
        "    from a string and parses the cleaned content as JSON.\n",
        "\n",
        "    Args:\n",
        "        output (str): The string containing a JSON object, possibly\n",
        "                      wrapped in Markdown code block syntax.\n",
        "\n",
        "    Returns:\n",
        "        dict: Parsed JSON object.\n",
        "\n",
        "    Raises:\n",
        "        json.JSONDecodeError: If the cleaned string is not valid JSON.\n",
        "    \"\"\"\n",
        "    # Remove markdown  ```json ... ```\n",
        "    cleaned = re.sub(r\"^```json|```$\", \"\", output.strip(), flags=re.MULTILINE).strip()\n",
        "\n",
        "    # Parsing\n",
        "    return json.loads(cleaned)\n",
        "\n",
        "class Billing:\n",
        "    \"\"\"\n",
        "    Extract and store billing information from HTTP response headers and body.\n",
        "\n",
        "    Attributes:\n",
        "        cost (Optional[float]): Response cost parsed from headers.\n",
        "        key_spend (Optional[float]): Key spend parsed from headers.\n",
        "        proxy_request_id (Optional[str]): Request ID extracted from the response body.\n",
        "        created (Optional[str]): Creation timestamp (converted from Unix time to ISO-8601).\n",
        "        raw_headers (Dict[str, str]): Raw response headers.\n",
        "    \"\"\"\n",
        "    def __init__(self, headers: Dict[str, str], body: Dict[str, str]):\n",
        "        \"\"\"\n",
        "        Initialize Billing object by parsing headers and response body.\n",
        "\n",
        "        Args:\n",
        "            headers (Dict[str, str]): HTTP response headers.\n",
        "            body (Dict[str, str]): HTTP response body.\n",
        "        \"\"\"\n",
        "        self.cost: Optional[float] = self._parse_float(headers.get(\"x-litellm-response-cost\"))\n",
        "        self.key_spend: Optional[float] = self._parse_float(headers.get(\"x-litellm-key-spend\"))\n",
        "        self.proxy_request_id: Optional[str] = body.get('id')\n",
        "        self.created: Optional[str] = self._parse_unix_time(body.get('created'))\n",
        "        self.raw_headers: Dict[str, str] = headers\n",
        "\n",
        "    @staticmethod\n",
        "    def _parse_float(value: Optional[str]) -> Optional[float]:\n",
        "        \"\"\"\n",
        "        Safely parse a string into a float.\n",
        "\n",
        "        Args:\n",
        "            value (Optional[str]): String to parse.\n",
        "\n",
        "        Returns:\n",
        "            Optional[float]: Parsed float value, or None if parsing fails.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return float(value) if value is not None else None\n",
        "        except ValueError:\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def _parse_unix_time(value: int) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Convert Unix timestamp to ISO-8601 formatted string in UTC-3 timezone.\n",
        "\n",
        "        Args:\n",
        "            value (int): Unix timestamp.\n",
        "\n",
        "        Returns:\n",
        "            Optional[str]: ISO-8601 formatted datetime string, or None if invalid.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            dt_utc = datetime.fromtimestamp(value, tz=timezone.utc)\n",
        "            return dt_utc.astimezone(timezone(timedelta(hours=-3))).isoformat()\n",
        "        except ValueError:\n",
        "            return None\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Optional[str]]:\n",
        "        \"\"\"\n",
        "        Convert the billing information into a dictionary.\n",
        "\n",
        "        Returns:\n",
        "            dict: Dictionary with billing information.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"cost\": self.cost,\n",
        "            \"key_spend\": self.key_spend,\n",
        "            \"proxy_request_id\": self.proxy_request_id,\n",
        "            \"created\": self.created\n",
        "        }\n",
        "\n",
        "\n",
        "class CustomHTTPClient(httpx.AsyncClient):\n",
        "    \"\"\"\n",
        "    Custom HTTP client that extends `httpx.AsyncClient` to capture billing information.\n",
        "\n",
        "    Attributes:\n",
        "        last_billing (Optional[Billing]): The last parsed billing information\n",
        "                                          from a response, or None if not available.\n",
        "    \"\"\"\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the custom HTTP client.\n",
        "\n",
        "        Args:\n",
        "            *args: Positional arguments passed to `httpx.AsyncClient`.\n",
        "            **kwargs: Keyword arguments passed to `httpx.AsyncClient`.\n",
        "        \"\"\"\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.last_billing: Optional[Billing] = None\n",
        "\n",
        "    async def send(self, request: httpx.Request, **kwargs) -> httpx.Response:\n",
        "        \"\"\"\n",
        "        Send an HTTP request and capture billing information from the response.\n",
        "\n",
        "        Args:\n",
        "            request (httpx.Request): The HTTP request to send.\n",
        "            **kwargs: Additional arguments for `httpx.AsyncClient.send`.\n",
        "\n",
        "        Returns:\n",
        "            httpx.Response: The HTTP response object.\n",
        "        \"\"\"\n",
        "        response = await super().send(request, **kwargs)\n",
        "        body = response.json()\n",
        "        self.last_billing = Billing(response.headers, body)\n",
        "        return response\n",
        "\n",
        "\n",
        "custom_client = CustomHTTPClient()\n",
        "\n",
        "# Model config\n",
        "model = OpenAIModel(\n",
        "        \"<path_to_model>\",\n",
        "        provider=OpenAIProvider(\n",
        "            api_key=\"<api_key>\",\n",
        "            base_url=\"<base_url>\",\n",
        "            http_client=custom_client\n",
        "        ),\n",
        "    )\n",
        "\n",
        "# Create the AI agent\n",
        "agent = Agent(model,\n",
        "             system_prompt=\"\"\" Você é um especialista em anonimização de textos médicos e sua tarefa é avaliar a qualidade da anonimização de um prontuário médico baseado em três critérios que são:\n",
        "            Desempenho técnico da anonimização, Perda de Informação e Risco de reidentificação.\n",
        "\n",
        "            Entrada:\n",
        "            Você receberá três versões do mesmo prontuário médico:\n",
        "\n",
        "            Original: Prontuário médico sem anonimização.\n",
        "            Anonimizado por especialista: Versão do prontuário que foi anonimizada manualmente por um especialista humano.\n",
        "            Anonimizado por modelo: Versão do prontuário que foi anonimizada por um modelo de linguagem.\n",
        "\n",
        "            Tarefa:\n",
        "            Avalie a versão anonimizada pelo modelo de linguagem em relação ao prontuário original e à versão anonimizada pelo especialista, utilizando os seguintes critérios:\n",
        "\n",
        "            Desempenho técnico da anonimização:\n",
        "\n",
        "            Avalie se todas as informações identificáveis (nomes, datas, endereços, telefone, nome de hospital, números de identificação de médicos e pacientes, etc.) foram corretamente removidas ou mascaradas.\n",
        "            Score 0 (péssimo) a 10 (perfeito).\n",
        "\n",
        "            Perda de informação (Information Loss):\n",
        "\n",
        "            Avalie se a anonimização preservou o máximo possível de informações úteis para análise clínica e treinamento de um modelo de deep learning em tarefas médicas,\n",
        "            mantendo a legibilidade e o valor semântico do texto comparado ao Original.\n",
        "            Score 0 (informação completamente perdida) a 10 (mínima perda de informação).\n",
        "\n",
        "            Capacidade de reidentificação humana (Human Reidentification Risk):\n",
        "\n",
        "            Avalie se um humano poderia reidentificar o paciente com base nas informações restantes no prontuário anonimizado. Quanto maior o risco, menor a nota.\n",
        "            Score 0 (altíssimo risco de reidentificação) a 10 (nenhuma chance de reidentificação).\n",
        "            Formato de saída:\n",
        "            Forneça a avaliação no seguinte formato JSON:\n",
        "\n",
        "            {\n",
        "              \"Desempenho\": {\n",
        "                \"score\": <score>,\n",
        "                \"text\": \"<explicação detalhada da nota atribuída>\"\n",
        "              },\n",
        "              \"Perda\": {\n",
        "                \"score\": <score>,\n",
        "                \"text\": \"<explicação detalhada da nota atribuída>\"\n",
        "              },\n",
        "              \"Reidentificação\": {\n",
        "                \"score\": <score>,\n",
        "                \"text\": \"<explicação detalhada da nota atribuída e entidades problemáticas>\"\n",
        "              }\n",
        "            }\n",
        "            Agora, analise os três prontuários fornecidos e gere a saída JSON.\n",
        "            No campo de texto dê um diagnóstico preciso e aprofundado explicando em detalhes o porquê da nota recebida.\n",
        "\n",
        "            \"\"\",)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b86b9ef6-0d34-47a3-8f45-1afe0e38a78b",
      "metadata": {
        "id": "b86b9ef6-0d34-47a3-8f45-1afe0e38a78b"
      },
      "outputs": [],
      "source": [
        "### Path to data generated during model inference on previous jupyter notebook\n",
        "generative_test_data_path = 'bert_generative_predictions.json'\n",
        "\n",
        "# Read data\n",
        "with open(generative_test_data_path, 'r') as file:\n",
        "    generative_test_set = json.load(file)\n",
        "\n",
        "len(generative_test_set), generative_test_set[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db01402e-c8a1-4a9d-bbc6-ace19596c3a4",
      "metadata": {
        "id": "db01402e-c8a1-4a9d-bbc6-ace19596c3a4"
      },
      "outputs": [],
      "source": [
        "list_preds = []\n",
        "for generative_pred in tqdm(generative_test_set[-200:]):\n",
        "\n",
        "    input_text = \"<<Prontuário não anonimizado:>> \" + generative_pred['text'] + '\\n\\n <<Prontuário anonimizado por especialista:>> ' + generative_pred['masked_text'] + '\\n\\n <<Prontuário anonimizado por modelo de linguagem:>> ' + generative_pred['prediction']\n",
        "\n",
        "    try:\n",
        "        # Run model\n",
        "        results = await agent.run(input_text)\n",
        "        list_preds.append(parse_json_from_code_block(results.output))\n",
        "    except:\n",
        "        print('JSON format error!')\n",
        "\n",
        "len(list_preds), list_preds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d728dc-e172-43eb-ace4-e73db741bf1b",
      "metadata": {
        "id": "58d728dc-e172-43eb-ace4-e73db741bf1b"
      },
      "outputs": [],
      "source": [
        "### Results\n",
        "list_performance = [pred['Desempenho']['score'] for pred in list_preds]\n",
        "list_loss = [pred['Perda']['score'] for pred in list_preds]\n",
        "list_reidentification = [pred['Reidentificação']['score'] for pred in list_preds]\n",
        "\n",
        "# Calculate the average of each list\n",
        "mean_performance = sum(list_performance) / len(list_performance) if list_performance else 0\n",
        "mean_loss = sum(list_loss) / len(list_loss) if list_loss else 0\n",
        "mean_reidentification = sum(list_reidentification) / len(list_reidentification) if list_reidentification else 0\n",
        "\n",
        "# Print Results\n",
        "print(list_performance)\n",
        "print(list_loss)\n",
        "print(list_reidentification)\n",
        "print('')\n",
        "print(f\"Average of Performance: {mean_performance:.2f}\")\n",
        "print(f\"Average of Information loss: {mean_loss:.2f}\")\n",
        "print(f\"Average of Reidentification Risk: {mean_reidentification:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b61f1dc-828f-44d2-b044-ef2b0c12ab0a",
      "metadata": {
        "id": "3b61f1dc-828f-44d2-b044-ef2b0c12ab0a"
      },
      "outputs": [],
      "source": [
        "# Number of reviews used as input to the model\n",
        "n_reviews = 25\n",
        "\n",
        "# Prepare data to generate the reports\n",
        "list_performance_text = [pred['Desempenho']['text'] for pred in list_preds[:n_reviews]]\n",
        "list_loss_text = [pred['Perda']['text'] for pred in list_preds[:n_reviews]]\n",
        "list_reidentification_text = [pred['Reidentificação']['text'] for pred in list_preds[:n_reviews]]\n",
        "\n",
        "list_performance_text_final = 'Desempenho técnico da anonimização \\n\\n<AVALIAÇAO> \\n' + '\\n\\n<AVALIAÇAO> \\n'.join(list_performance_text)\n",
        "list_loss_text_final = 'Perda de informação \\n\\n<AVALIAÇAO> \\n' + '\\n\\n<AVALIAÇAO> \\n'.join(list_loss_text)\n",
        "list_reidentification_text_final = 'Risco de reidentificação humana \\n\\n<AVALIAÇAO> \\n' + '\\n\\n<AVALIAÇAO> \\n'.join(list_reidentification_text)\n",
        "print(list_performance_text_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21bf2507-fb2b-46ad-a4fa-387ad87e7b34",
      "metadata": {
        "id": "21bf2507-fb2b-46ad-a4fa-387ad87e7b34"
      },
      "outputs": [],
      "source": [
        "# Model that generates the reports\n",
        "agent_sum = Agent(model,\n",
        "             system_prompt=\"\"\" Você é um especialista em privacidade de dados médicos e anonimização de textos clínicos.\n",
        "             Sua tarefa é analisar uma lista de avaliações sobre prontuários médicos que foram anonimizados por um modelo de linguagem.\n",
        "\n",
        "             Cada entrada da lista representa a avaliação de um prontuário que leva em consideração um desses três aspectos:\n",
        "\n",
        "             1. **Desempenho técnico da anonimização** – quão bem as informações sensíveis foram removidas ou mascaradas.\n",
        "             2. **Perda de informação** – o quanto a utilidade clínica do texto foi preservada após a anonimização.\n",
        "             3. **Risco de reidentificação humana** – a possibilidade de que um humano consiga identificar o paciente com base nas informações restantes.\n",
        "\n",
        "             Sua tarefa é gerar um relatório que:\n",
        "\n",
        "             - Identifique **tendências gerais** nas avaliações para o critério especificado.\n",
        "             - Destaque **pontos fortes e fracos recorrentes** destacados nas avaliações para o critério especificado.\n",
        "             - Indique os principais problemas destacados nas avaliações para o critério especificado.\n",
        "\n",
        "             No início do texto estará indicado qual critério deverá ser avaliado.\n",
        "\n",
        "             Formato da saída:\n",
        "             - Um parágrafo ou dois com até 300 palavras.\n",
        "             - Não repita todos os diagnósticos, mas **sintetize os achados globais**.\n",
        "\n",
        "             Diagnósticos de entrada:\n",
        "             <<INSIRA AQUI A LISTA DE AVALIAÇÕES GERADAS>>\n",
        "             \"\"\",)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6eb3e84-35f2-4cd3-8077-4ed9de66b6dc",
      "metadata": {
        "id": "b6eb3e84-35f2-4cd3-8077-4ed9de66b6dc"
      },
      "outputs": [],
      "source": [
        "# Generate report for each criteria\n",
        "list_reports = []\n",
        "for input_str in [list_performance_text_final, list_loss_text_final, list_reidentification_text_final]:\n",
        "\n",
        "    # Run model\n",
        "    results_ = await agent_sum.run(input_str)\n",
        "    list_reports.append(results_.output)\n",
        "\n",
        "len(list_reports), list_reports[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1524499e-bdc6-4f43-b37c-dbb985a057dd",
      "metadata": {
        "id": "1524499e-bdc6-4f43-b37c-dbb985a057dd"
      },
      "outputs": [],
      "source": [
        "# Output path\n",
        "caminho_arquivo = \"report_bert.json\"\n",
        "\n",
        "# Save JSON\n",
        "with open(caminho_arquivo, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(list_reports, f, indent=2, ensure_ascii=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}